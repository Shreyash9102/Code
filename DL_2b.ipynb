{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rBm_RrVixaxm"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The reviews are already converted into sequences of integers, where each integer represents a word in a dictionary.\n",
        "\n",
        " Function Vectorize_sequence This is also known as one-hot encoding. The result is a binary matrix that indicates the presence or absence of each word in each review.\n"
      ],
      "metadata": {
        "id": "5RS7tVxc8vpS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the number of words to consider as features\n",
        "vocab_size = 10000\n",
        "\n",
        "# Load data\n",
        "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=vocab_size)\n",
        "\n",
        "# A function to vectorize the sequences into 2D tensor\n",
        "def vectorize_sequences(sequences, dimension=vocab_size):\n",
        "    results = np.zeros((len(sequences), dimension))\n",
        "    for i, sequence in enumerate(sequences):\n",
        "        results[i, sequence] = 1.\n",
        "    return results\n",
        "\n",
        "# Vectorize data\n",
        "x_train = vectorize_sequences(train_data)\n",
        "x_test = vectorize_sequences(test_data)\n",
        "y_train = np.array(train_labels).astype(\"float32\")\n",
        "y_test = np.array(test_labels).astype(\"float32\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WlsplEEly3Pe",
        "outputId": "575e3d2f-227f-40fe-9d27-ddc9f7297c0e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17464789/17464789 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model definition\n",
        "model = Sequential([\n",
        "    Dense(16, activation='relu', input_shape=(vocab_size,)),\n",
        "    Dense(16, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "ajP_v9Oey3Mw"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit(x_train, y_train, epochs=10, batch_size=512, validation_split=0.2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eqda7wT4y3Jo",
        "outputId": "f397cab6-5959-454f-ab67-55c621388d5e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "40/40 [==============================] - 2s 22ms/step - loss: 0.5195 - accuracy: 0.7661 - val_loss: 0.3537 - val_accuracy: 0.8810\n",
            "Epoch 2/10\n",
            "40/40 [==============================] - 1s 15ms/step - loss: 0.2711 - accuracy: 0.9083 - val_loss: 0.2848 - val_accuracy: 0.8906\n",
            "Epoch 3/10\n",
            "40/40 [==============================] - 1s 15ms/step - loss: 0.1924 - accuracy: 0.9340 - val_loss: 0.2858 - val_accuracy: 0.8870\n",
            "Epoch 4/10\n",
            "40/40 [==============================] - 1s 15ms/step - loss: 0.1501 - accuracy: 0.9503 - val_loss: 0.2927 - val_accuracy: 0.8902\n",
            "Epoch 5/10\n",
            "40/40 [==============================] - 1s 13ms/step - loss: 0.1208 - accuracy: 0.9624 - val_loss: 0.3089 - val_accuracy: 0.8878\n",
            "Epoch 6/10\n",
            "40/40 [==============================] - 1s 15ms/step - loss: 0.0997 - accuracy: 0.9706 - val_loss: 0.3411 - val_accuracy: 0.8792\n",
            "Epoch 7/10\n",
            "40/40 [==============================] - 1s 15ms/step - loss: 0.0842 - accuracy: 0.9761 - val_loss: 0.3583 - val_accuracy: 0.8794\n",
            "Epoch 8/10\n",
            "40/40 [==============================] - 1s 15ms/step - loss: 0.0685 - accuracy: 0.9830 - val_loss: 0.3884 - val_accuracy: 0.8742\n",
            "Epoch 9/10\n",
            "40/40 [==============================] - 1s 15ms/step - loss: 0.0554 - accuracy: 0.9883 - val_loss: 0.4199 - val_accuracy: 0.8758\n",
            "Epoch 10/10\n",
            "40/40 [==============================] - 1s 13ms/step - loss: 0.0446 - accuracy: 0.9916 - val_loss: 0.4514 - val_accuracy: 0.8754\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "results = model.evaluate(x_test, y_test)\n",
        "print(f\"Test Loss: {results[0]} - Test Accuracy: {results[1]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xbcvGUoQy3Gn",
        "outputId": "b11ef3d5-bd98-481e-c518-d1b66f803b6a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 1s 2ms/step - loss: 0.4804 - accuracy: 0.8617\n",
            "Test Loss: 0.48037055134773254 - Test Accuracy: 0.8617200255393982\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example review (replace with any text)\n",
        "review = \"This movie was excellent! The performances were outstanding and I was captivated from start to finish.\"\n",
        "\n",
        "# Convert review to tokens\n",
        "def review_to_tokens(review):\n",
        "    word_index = imdb.get_word_index()\n",
        "    tokens = [word_index.get(w, 0) for w in review.lower().split()]\n",
        "    return vectorize_sequences([tokens])\n",
        "\n",
        "# Predict the sentiment\n",
        "prediction = model.predict(review_to_tokens(review))\n",
        "print(\"Review sentiment (0=negative, 1=positive):\", prediction[0,0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NaDfSV6Jy3Dw",
        "outputId": "65a5a076-d9d4-4652-f4f9-afc87b0e6552"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 16ms/step\n",
            "Review sentiment (0=negative, 1=positive): 0.8027048\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "D1bIgU8W16wj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}