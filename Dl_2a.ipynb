{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "CEvV-3yAzkaV"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/letter-recognition/letter-recognition.data\"\n",
        "data = pd.read_csv(url, header=None)\n",
        "\n",
        "# Define column names\n",
        "columns = ['letter', 'x-box', 'y-box', 'width', 'height', 'onpix', 'x-bar', 'y-bar', 'x2bar', 'y2bar', 'xybar', 'x2ybr', 'xy2br', 'x-ege', 'xegvy', 'y-ege', 'yegvx']\n",
        "data.columns = columns\n",
        "\n",
        "# Extract features and labels\n",
        "X = data.drop('letter', axis=1)\n",
        "y = data['letter']\n",
        "\n",
        "# Encode target labels\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "7CdA5k8y5d2S"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model architecture\n",
        "model = Sequential([\n",
        "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(26, activation='softmax')  # Output layer: 26 units for 26 classes\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "kT41ZBg55dvk"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=30, batch_size=128, validation_split=0.1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDn0Wgeq7B1e",
        "outputId": "43ad6a66-6f99-499d-a093-621f169d793d"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 2.7637 - accuracy: 0.2582 - val_loss: 1.9324 - val_accuracy: 0.5069\n",
            "Epoch 2/30\n",
            "113/113 [==============================] - 0s 3ms/step - loss: 1.5550 - accuracy: 0.5885 - val_loss: 1.2934 - val_accuracy: 0.6500\n",
            "Epoch 3/30\n",
            "113/113 [==============================] - 0s 3ms/step - loss: 1.1580 - accuracy: 0.6869 - val_loss: 1.0696 - val_accuracy: 0.7106\n",
            "Epoch 4/30\n",
            "113/113 [==============================] - 0s 3ms/step - loss: 0.9871 - accuracy: 0.7339 - val_loss: 0.9682 - val_accuracy: 0.7462\n",
            "Epoch 5/30\n",
            "113/113 [==============================] - 0s 3ms/step - loss: 0.8889 - accuracy: 0.7576 - val_loss: 0.9001 - val_accuracy: 0.7538\n",
            "Epoch 6/30\n",
            "113/113 [==============================] - 0s 3ms/step - loss: 0.8159 - accuracy: 0.7751 - val_loss: 0.8339 - val_accuracy: 0.7775\n",
            "Epoch 7/30\n",
            "113/113 [==============================] - 0s 3ms/step - loss: 0.7653 - accuracy: 0.7882 - val_loss: 0.7611 - val_accuracy: 0.7919\n",
            "Epoch 8/30\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.7164 - accuracy: 0.7996 - val_loss: 0.7139 - val_accuracy: 0.8125\n",
            "Epoch 9/30\n",
            "113/113 [==============================] - 1s 4ms/step - loss: 0.6821 - accuracy: 0.8078 - val_loss: 0.6928 - val_accuracy: 0.8094\n",
            "Epoch 10/30\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.6428 - accuracy: 0.8161 - val_loss: 0.6459 - val_accuracy: 0.8200\n",
            "Epoch 11/30\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 0.6100 - accuracy: 0.8278 - val_loss: 0.6230 - val_accuracy: 0.8250\n",
            "Epoch 12/30\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.5832 - accuracy: 0.8327 - val_loss: 0.5971 - val_accuracy: 0.8388\n",
            "Epoch 13/30\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.5568 - accuracy: 0.8387 - val_loss: 0.5815 - val_accuracy: 0.8363\n",
            "Epoch 14/30\n",
            "113/113 [==============================] - 0s 3ms/step - loss: 0.5331 - accuracy: 0.8433 - val_loss: 0.5550 - val_accuracy: 0.8469\n",
            "Epoch 15/30\n",
            "113/113 [==============================] - 0s 3ms/step - loss: 0.5084 - accuracy: 0.8517 - val_loss: 0.5407 - val_accuracy: 0.8394\n",
            "Epoch 16/30\n",
            "113/113 [==============================] - 0s 3ms/step - loss: 0.4976 - accuracy: 0.8528 - val_loss: 0.5209 - val_accuracy: 0.8531\n",
            "Epoch 17/30\n",
            "113/113 [==============================] - 0s 3ms/step - loss: 0.4771 - accuracy: 0.8575 - val_loss: 0.4970 - val_accuracy: 0.8562\n",
            "Epoch 18/30\n",
            "113/113 [==============================] - 0s 3ms/step - loss: 0.4597 - accuracy: 0.8635 - val_loss: 0.4883 - val_accuracy: 0.8625\n",
            "Epoch 19/30\n",
            "113/113 [==============================] - 0s 3ms/step - loss: 0.4429 - accuracy: 0.8694 - val_loss: 0.4765 - val_accuracy: 0.8681\n",
            "Epoch 20/30\n",
            "113/113 [==============================] - 0s 3ms/step - loss: 0.4309 - accuracy: 0.8701 - val_loss: 0.4736 - val_accuracy: 0.8612\n",
            "Epoch 21/30\n",
            "113/113 [==============================] - 0s 3ms/step - loss: 0.4190 - accuracy: 0.8742 - val_loss: 0.4465 - val_accuracy: 0.8719\n",
            "Epoch 22/30\n",
            "113/113 [==============================] - 0s 3ms/step - loss: 0.4005 - accuracy: 0.8799 - val_loss: 0.4288 - val_accuracy: 0.8700\n",
            "Epoch 23/30\n",
            "113/113 [==============================] - 0s 3ms/step - loss: 0.3978 - accuracy: 0.8796 - val_loss: 0.4274 - val_accuracy: 0.8750\n",
            "Epoch 24/30\n",
            "113/113 [==============================] - 0s 3ms/step - loss: 0.3841 - accuracy: 0.8831 - val_loss: 0.4281 - val_accuracy: 0.8725\n",
            "Epoch 25/30\n",
            "113/113 [==============================] - 0s 3ms/step - loss: 0.3771 - accuracy: 0.8860 - val_loss: 0.4115 - val_accuracy: 0.8731\n",
            "Epoch 26/30\n",
            "113/113 [==============================] - 0s 3ms/step - loss: 0.3597 - accuracy: 0.8915 - val_loss: 0.3855 - val_accuracy: 0.8906\n",
            "Epoch 27/30\n",
            "113/113 [==============================] - 0s 3ms/step - loss: 0.3502 - accuracy: 0.8928 - val_loss: 0.3770 - val_accuracy: 0.8769\n",
            "Epoch 28/30\n",
            "113/113 [==============================] - 0s 3ms/step - loss: 0.3416 - accuracy: 0.8949 - val_loss: 0.3742 - val_accuracy: 0.8888\n",
            "Epoch 29/30\n",
            "113/113 [==============================] - 0s 3ms/step - loss: 0.3307 - accuracy: 0.8991 - val_loss: 0.3739 - val_accuracy: 0.8856\n",
            "Epoch 30/30\n",
            "113/113 [==============================] - 0s 3ms/step - loss: 0.3213 - accuracy: 0.9025 - val_loss: 0.3564 - val_accuracy: 0.8956\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on test data\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test accuracy: {accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFq3_CSC7Ew1",
        "outputId": "f243098f-cf8e-4177-aab4-f12a4d443eb9"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3424 - accuracy: 0.8942\n",
            "Test accuracy: 0.8942499756813049\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a prediction\n",
        "sample = X_test.iloc[0]\n",
        "prediction = model.predict(tf.expand_dims(sample, axis=0))\n",
        "predicted_class = label_encoder.inverse_transform([np.argmax(prediction)])\n",
        "print(f\"Predicted class: {predicted_class[0]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D4LSnCmC7J92",
        "outputId": "41207153-f9aa-4bcc-c555-041cd995b057"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 23ms/step\n",
            "Predicted class: Z\n"
          ]
        }
      ]
    }
  ]
}